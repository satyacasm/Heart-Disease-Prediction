{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2250/1457845952.py:13: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  statlog_data = pd.read_csv(statlog_url, names=statlog_column_names, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  70.0  1.0  4.0     130.0  322.0  0.0      2.0    109.0    0.0      2.4   \n",
      "1  67.0  0.0  3.0     115.0  564.0  0.0      2.0    160.0    0.0      1.6   \n",
      "2  57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
      "3  64.0  1.0  4.0     128.0  263.0  0.0      0.0    105.0    1.0      0.2   \n",
      "4  74.0  0.0  2.0     120.0  269.0  0.0      2.0    121.0    1.0      0.2   \n",
      "\n",
      "   slope   ca  thal  target  \n",
      "0    2.0  3.0   1.0       1  \n",
      "1    2.0  0.0   3.0       0  \n",
      "2    1.0  0.0   3.0       1  \n",
      "3    2.0  1.0   3.0       0  \n",
      "4    1.0  1.0   1.0       0  \n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope   \n",
      "1   63    1   0       145   233    1        2      150      0      2.3      2   \n",
      "2   67    1   3       160   286    0        2      108      1      1.5      1   \n",
      "3   67    1   3       120   229    0        2      129      1      2.6      1   \n",
      "4   37    1   2       130   250    0        0      187      0      3.5      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0  ca  thal  target  \n",
      "1   0     2       0  \n",
      "2   3     1       1  \n",
      "3   2     3       1  \n",
      "4   0     1       0  \n",
      "574\n"
     ]
    }
   ],
   "source": [
    "# Load the Cleveland Heart Disease dataset\n",
    "cleveland_data = pd.read_csv('Heart_disease_cleveland_new.csv', names=[\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\",\n",
    "    \"slope\", \"ca\", \"thal\", \"target\"\n",
    "], na_values='?')\n",
    "\n",
    "# Load the Statlog (Heart) dataset\n",
    "statlog_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat\"\n",
    "statlog_column_names = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\",\n",
    "    \"slope\", \"ca\", \"thal\", \"target\"\n",
    "]\n",
    "statlog_data = pd.read_csv(statlog_url, names=statlog_column_names, delim_whitespace=True)\n",
    "# Adjust 'slope' and 'thal' values in Statlog dataset to match Cleveland dataset\n",
    "statlog_data['slope'] = statlog_data['slope'].replace({1: 1, 2: 2, 3: 0})\n",
    "statlog_data['thal'] = statlog_data['thal'].replace({3: 1, 6: 2, 7: 3})\n",
    "statlog_data['target'] = statlog_data['target'].replace({1: 0, 2: 1})\n",
    "print(statlog_data.head())\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([cleveland_data, statlog_data])\n",
    "# Display the rows where the target value is 2\n",
    "# target_2_data = cleveland_data[cleveland_data['target'] == 2]\n",
    "# print(target_2_data.head())\n",
    "# print(len(target_2_data.index))\n",
    "# Display the first few rows of the combined dataset\n",
    "print(data.head())\n",
    "print(len(data.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = pd.to_numeric(data['target'], errors='coerce')\n",
    "# Handle missing values by dropping rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert target column to integer type\n",
    "data['target'] = data['target'].astype(int)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target'].apply(lambda x: 1 if x > 0 else 0)  # Convert target to binary\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JellyFish Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JellyfishOptimizationAlgorithm:\n",
    "    def __init__(self, population_size, dimensions, lower_bound, upper_bound, max_iter, b=0.5, alpha=1.5):\n",
    "        self.population_size = population_size\n",
    "        self.dimensions = dimensions\n",
    "        self.lower_bound = np.array(lower_bound)\n",
    "        self.upper_bound = np.array(upper_bound)\n",
    "        self.max_iter = max_iter\n",
    "        self.b = b  # Distribution coefficient\n",
    "        self.alpha = alpha  # Alpha controls the movement step size\n",
    "        self.population = self.initialize_population()\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = -1\n",
    "\n",
    "    def initialize_population(self):\n",
    "        return np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dimensions))\n",
    "\n",
    "    def ocean_current(self, individual, mean_location):\n",
    "        r = random.random()\n",
    "        trend = self.best_solution - self.b * mean_location * r\n",
    "        new_position = individual + r * trend\n",
    "        return np.clip(new_position, self.lower_bound, self.upper_bound)\n",
    "\n",
    "    def passive_motion(self, individual):\n",
    "        new_position = individual + (self.upper_bound - self.lower_bound) * np.random.random(self.dimensions)\n",
    "        return np.clip(new_position, self.lower_bound, self.upper_bound)\n",
    "\n",
    "    def active_motion(self, individual):\n",
    "        r = random.random()\n",
    "        new_position = individual + self.alpha * r * (self.best_solution - individual)\n",
    "        return np.clip(new_position, self.lower_bound, self.upper_bound)\n",
    "\n",
    "    def optimize(self, fitness_function):\n",
    "        self.best_solution = None\n",
    "        self.best_fitness = -1\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            c_t = iteration / self.max_iter\n",
    "            mean_location = np.mean(self.population, axis=0)\n",
    "\n",
    "            for i in range(self.population_size):\n",
    "                individual = self.population[i]\n",
    "                fitness_value = fitness_function(individual)\n",
    "                if fitness_value > self.best_fitness:\n",
    "                    self.best_fitness = fitness_value\n",
    "                    self.best_solution = individual\n",
    "\n",
    "            new_population = np.zeros_like(self.population)\n",
    "            for i in range(self.population_size):\n",
    "                if c_t < 0.5:\n",
    "                    new_population[i] = self.ocean_current(self.population[i], mean_location)\n",
    "                else:\n",
    "                    if 1 - c_t < random.random():\n",
    "                        new_population[i] = self.passive_motion(self.population[i])\n",
    "                    else:\n",
    "                        new_population[i] = self.active_motion(self.population[i])\n",
    "\n",
    "            self.population = new_population\n",
    "\n",
    "            # print(f\"Iteration {iteration + 1}/{self.max_iter}, Best Fitness: {self.best_fitness}\")\n",
    "\n",
    "        return self.best_solution, self.best_fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution (C): 29.167800629847573, Best fitness: 0.8646288209606987\n",
      "Accuracy: 0.8434782608695652\n",
      "Precision: 0.8636363636363636\n",
      "Recall: 0.76\n",
      "F1 Score: 0.8085106382978723\n",
      "ROC AUC Score: 0.8338461538461539\n"
     ]
    }
   ],
   "source": [
    "# Define the bounds for C parameter of the Logistic Regression\n",
    "lower_bound = [0.001]\n",
    "upper_bound = [100]\n",
    "\n",
    "# Instantiate the Jellyfish Optimization Algorithm\n",
    "joa = JellyfishOptimizationAlgorithm(\n",
    "    population_size=30, dimensions=1, lower_bound=lower_bound, upper_bound=upper_bound, max_iter=50\n",
    ")\n",
    "\n",
    "def logistic_regression_fitness(solution):\n",
    "    C = solution[0]\n",
    "    model = LogisticRegression(C=C, solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Optimize the Logistic Regression parameters using JOA\n",
    "best_solution, best_fitness = joa.optimize(logistic_regression_fitness)\n",
    "print(f\"Best solution (C): {best_solution[0]}, Best fitness: {best_fitness}\")\n",
    "\n",
    "# Train the Logistic Regression model with the best parameter\n",
    "model = LogisticRegression(C=best_solution[0], solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
