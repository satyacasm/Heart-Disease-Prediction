{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Cleveland Heart Disease Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1508/1457845952.py:13: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  statlog_data = pd.read_csv(statlog_url, names=statlog_column_names, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  70.0  1.0  4.0     130.0  322.0  0.0      2.0    109.0    0.0      2.4   \n",
      "1  67.0  0.0  3.0     115.0  564.0  0.0      2.0    160.0    0.0      1.6   \n",
      "2  57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
      "3  64.0  1.0  4.0     128.0  263.0  0.0      0.0    105.0    1.0      0.2   \n",
      "4  74.0  0.0  2.0     120.0  269.0  0.0      2.0    121.0    1.0      0.2   \n",
      "\n",
      "   slope   ca  thal  target  \n",
      "0    2.0  3.0   1.0       1  \n",
      "1    2.0  0.0   3.0       0  \n",
      "2    1.0  0.0   3.0       1  \n",
      "3    2.0  1.0   3.0       0  \n",
      "4    1.0  1.0   1.0       0  \n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope   \n",
      "1   63    1   0       145   233    1        2      150      0      2.3      2   \n",
      "2   67    1   3       160   286    0        2      108      1      1.5      1   \n",
      "3   67    1   3       120   229    0        2      129      1      2.6      1   \n",
      "4   37    1   2       130   250    0        0      187      0      3.5      2   \n",
      "\n",
      "   ca  thal  target  \n",
      "0  ca  thal  target  \n",
      "1   0     2       0  \n",
      "2   3     1       1  \n",
      "3   2     3       1  \n",
      "4   0     1       0  \n",
      "574\n"
     ]
    }
   ],
   "source": [
    "# Load the Cleveland Heart Disease dataset\n",
    "cleveland_data = pd.read_csv('Heart_disease_cleveland_new.csv', names=[\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\",\n",
    "    \"slope\", \"ca\", \"thal\", \"target\"\n",
    "], na_values='?')\n",
    "\n",
    "# Load the Statlog (Heart) dataset\n",
    "statlog_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat\"\n",
    "statlog_column_names = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \"exang\", \"oldpeak\",\n",
    "    \"slope\", \"ca\", \"thal\", \"target\"\n",
    "]\n",
    "statlog_data = pd.read_csv(statlog_url, names=statlog_column_names, delim_whitespace=True)\n",
    "# Adjust 'slope' and 'thal' values in Statlog dataset to match Cleveland dataset\n",
    "statlog_data['slope'] = statlog_data['slope'].replace({1: 1, 2: 2, 3: 0})\n",
    "statlog_data['thal'] = statlog_data['thal'].replace({3: 1, 6: 2, 7: 3})\n",
    "statlog_data['target'] = statlog_data['target'].replace({1: 0, 2: 1})\n",
    "print(statlog_data.head())\n",
    "\n",
    "# Combine the datasets\n",
    "data = pd.concat([cleveland_data, statlog_data])\n",
    "# Display the rows where the target value is 2\n",
    "# target_2_data = cleveland_data[cleveland_data['target'] == 2]\n",
    "# print(target_2_data.head())\n",
    "# print(len(target_2_data.index))\n",
    "# Display the first few rows of the combined dataset\n",
    "print(data.head())\n",
    "print(len(data.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = pd.to_numeric(data['target'], errors='coerce')\n",
    "# Handle missing values by dropping rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert target column to integer type\n",
    "data['target'] = data['target'].astype(int)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target'].apply(lambda x: 1 if x > 0 else 0)  # Convert target to binary\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JellyFish Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JellyfishOptimizationAlgorithm:\n",
    "    def __init__(self, population_size, dimensions, lower_bound, upper_bound, max_iter):\n",
    "        self.population_size = population_size\n",
    "        self.dimensions = dimensions\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.max_iter = max_iter\n",
    "        self.population = self.initialize_population()\n",
    "\n",
    "    def initialize_population(self):\n",
    "        return np.random.uniform(self.lower_bound, self.upper_bound, (self.population_size, self.dimensions))\n",
    "\n",
    "    def fitness(self, solution):\n",
    "        # Ensure gamma is a positive value\n",
    "        C = solution[0]\n",
    "        gamma = abs(solution[1])  # Taking absolute value to ensure gamma is positive\n",
    "        model = SVC(C=C, gamma=gamma, kernel='rbf')\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_train)\n",
    "        accuracy = accuracy_score(y_train, predictions)\n",
    "        return accuracy\n",
    "\n",
    "    def optimize(self):\n",
    "        best_solution = None\n",
    "        best_fitness = -1\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            for individual in self.population:\n",
    "                fitness_value = self.fitness(individual)\n",
    "                if fitness_value > best_fitness:\n",
    "                    best_fitness = fitness_value\n",
    "                    best_solution = individual\n",
    "\n",
    "            # Update population\n",
    "            for i in range(self.population_size):\n",
    "                if random.random() < 0.5:\n",
    "                    self.population[i] = best_solution + np.random.uniform(-1, 1, self.dimensions)\n",
    "                else:\n",
    "                    self.population[i] = np.random.uniform(self.lower_bound, self.upper_bound, self.dimensions)\n",
    "\n",
    "        return best_solution, best_fitness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SVM with JOA to predict heart diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution (C, gamma): [8.67671283 1.07303811], Best fitness: 1.0\n",
      "Accuracy: 0.8434782608695652\n",
      "Precision: 0.9210526315789473\n",
      "Recall: 0.7\n",
      "F1 Score: 0.7954545454545454\n",
      "ROC AUC Score: 0.8269230769230769\n"
     ]
    }
   ],
   "source": [
    "# Define the bounds for C and gamma parameters of the SVM\n",
    "lower_bound = [0.1, 0.001]\n",
    "upper_bound = [100, 1]\n",
    "\n",
    "# Instantiate the Jellyfish Optimization Algorithm\n",
    "joa = JellyfishOptimizationAlgorithm(\n",
    "    population_size=30, dimensions=2, lower_bound=lower_bound, upper_bound=upper_bound, max_iter=50\n",
    ")\n",
    "\n",
    "# Optimize the SVM parameters using JOA\n",
    "best_solution, best_fitness = joa.optimize()\n",
    "print(f\"Best solution (C, gamma): {best_solution}, Best fitness: {best_fitness}\")\n",
    "\n",
    "# Train the SVM model with the best parameters\n",
    "model = SVC(C=best_solution[0], gamma=best_solution[1], kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
